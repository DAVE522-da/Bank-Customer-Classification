import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

churn = pd.read_csv(r"C:\Users\User\Desktop\data analysis\PYTHON\projects\Bank Customer Churn\Bank+Customer+Churn\Bank_Churn.csv")
churn.head()

churn.info()

churn.describe()

sns.heatmap(churn.corr(numeric_only=True), vmin=-1, vmax=1, cmap="coolwarm") 
# Heatmap matrix to find relationships between all pairs of numeric columns 
# Number of products is negatively correlated with balance

for col in churn.select_dtypes("number"):
    sns.boxplot(data=churn, x="Exited", y=col)
    plt.show()

# Median age between churners and non churners is 10 years
# Customers with a lot of tenure and a little tenyre are much likley to churn
# Customers with higher balance tend to churn

for col in churn.select_dtypes("object").columns[1:]:
    sns.barplot(data=churn, x="Exited", y=col)
    plt.show()

# Germany has the highest churn rate - 33%, compare to Spain and France - 16% and 15% accordingly.
# Females tend to churn 8% more than males

# Preparing the data for modeling

# Dropping unnecessary columns from the dataset:
churn_modelling_df = churn.drop(["CustomerId", "Surname"], axis=1)

#  Creating two new features by adding additional columns to the DataFrame:
#    - "balance_to_income": This new feature is created by dividing the "Balance" column by the "EstimatedSalary" column.
#      It provides an indicator of how a customer's balance compares to their estimated salary, which might be useful 
#      for predicting churn.
#    - "income_vs_products": This new feature is created by dividing the "EstimatedSalary" by the "NumOfProducts".
#      This shows how much income each customer generates in relation to the number of products they have with the bank,
#      which could be important for assessing customer value.
churn_modelling_df = churn_modelling_df.assign(
    balance_to_income = churn_modelling_df["Balance"] / churn_modelling_df["EstimatedSalary"],
    income_vs_products = churn_modelling_df["EstimatedSalary"] / churn_modelling_df["NumOfProducts"]
)
churn_modelling_df.head()

sns.boxplot(churn_modelling_df.query("balance_to_income < 10"), x="Exited", y="balance_to_income")
# churners have slightly higher balance to income rate

sns.boxplot(churn_modelling_df, x="Exited", y="income_vs_products")
# A gap of 5,000 between the medians

# Using pd.get_dummies to perform one-hot encoding on the categorical columns in the DataFrame.
churn_modelling_df = pd.get_dummies(churn_modelling_df, drop_first=True, dtype="int")
churn_modelling_df

#Split the data into train and test sets, with 20% of the rows in the test set
from sklearn.model_selection import train_test_split
X = churn_modelling_df.drop("Exited", axis=1)
y = churn_modelling_df["Exited"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)

#Fitting a logistic regression model on the training data

from sklearn.linear_model import LogisticRegression
# Creating a LogisticRegression model with the "newton-cholesky" solver.
# This solver is chosen as it is efficient for models with many parameters and avoids numerical issues.
logreg = LogisticRegression(solver="newton-cholesky")
#  Fit the Logistic Regression model on the training data
lr = logreg.fit(X_train, y_train)

print(f"Train Accuracy: {lr.score(X_train, y_train)}")

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

confusion_matrix(y_train, lr.predict(X_train))

precision_score(y_train, lr.predict(X_train))

recall_score(y_train, lr.predict(X_train))

f1_score(y_train, lr.predict(X_train))

list(zip(X_train,lr.coef_[0]))

confusion_matrix(y_test, lr.predict(X_test))

print(f"Test Accuracy: {lr.score(X_test, y_test)}")

precision_score(y_test,lr.predict(X_test))

recall_score(y_test,lr.predict(X_test))

f1_score(y_test, lr.predict(X_test))

from sklearn.metrics import roc_curve, auc
#  Predicting the probabilities of the positive class (churn) using the model on the test data.
#  lr.predict_proba() gives probabilities for both classes; [:, 1] extracts the probabilities for the positive class (churn).
y_probs = lr.predict_proba(X_test) [:, 1]
#Calculate the False Positive Rate (fpr), True Positive Rate (tpr), and thresholds using roc_curve.
fpr1, tpr1, thresholds = roc_curve(y_test, y_probs)
# Calculate the Area Under the Curve (AUC) score, which provides a single value summarizing the model's performance.
#  AUC ranges from 0 to 1, where 1 means a perfect classifier and 0.5 means random guessing.
auc_score = auc(fpr1, tpr1)


plt.plot(fpr1, tpr1, label=f'LR (AUC = {auc_score:.2f})')


plt.plot([0,1], [0,1], 'k--', label = 'Random Guess (AUC = 0.50)')


plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Roc Curves for Bank Churn Model')
plt.legend()
plt.show()

from sklearn.metrics import precision_recall_curve
p_curve, r_curve, t_curve = precision_recall_curve(y_train, lr.predict_proba(X_train)[:,1])

plt.plot(t_curve, p_curve[:-1], label='Precision')
plt.plot(t_curve, r_curve[:-1], label='Recall')
plt.xlabel('Prediction Threshold')
plt.ylabel('Scores')
plt.title('Precision & Recall Curves')
plt.legend()
plt.show()

import numpy as np
np.where(p_curve > .5) 

t_curve[6377]

confusion_matrix(y_test, lr.predict_proba(X_test)[:,1] > .32 )

recall_score(y_test, lr.predict_proba(X_test)[:,1] > .32)

precision_score(y_test, lr.predict_proba(X_test)[:,1] > .32)

# fit a random forest model, tuning it using cross validation, and evaluate test accuracy, AUC score, and feature importance.

from sklearn.ensemble import RandomForestClassifier


rf = RandomForestClassifier()


rf = rf.fit(X_train, y_train)


print(f"Train Accuracy: {rf.score(X_train, y_train)}")


print(f"Test Accuracy: {rf.score(X_test, y_test)}")


# Perform hyperparameter tuning for RandomForestClassifier using RandomizedSearchCV
from sklearn.model_selection import RandomizedSearchCV


rf = RandomForestClassifier(random_state=2023, n_jobs=-1)


params = {
    'n_estimators': np.arange(start=100, stop=1100, step=100),  # Number of trees: 100 to 1000, step 100
    'max_features': [None, "sqrt"],  # Max features: all or square root of total
    'bootstrap': [True],  # Always use bootstrapping
    'max_samples': [None, .3, .5, .9],  # Fraction of samples to draw for each tree
    'max_depth': np.arange(start=1, stop=11, step=1),  # Maximum tree depth: 1 to 10
    'min_samples_leaf': [2,5,10,20,100],  # Minimum samples required at a leaf node
}


grid = RandomizedSearchCV(
    rf,  # The model to tune
    params,  # Hyperparameter search space
    n_iter=100,  # Number of parameter settings sampled
    scoring="accuracy"  # Metric to optimize
)

#
grid.fit(X_train, y_train)


grid.best_params_

from sklearn.model_selection import GridSearchCV



rf = RandomForestClassifier(random_state=2023, n_jobs=-1)  


params = {
    'n_estimators': np.arange(start=850, stop=951, step=50),  # Fewer combinations
    'max_samples': [0.4, 0.5],  # Reduced range
    'max_depth': [8, 10],  # Reduced depth options
    'min_samples_leaf': [5, 10]  # Fewer leaf options
}

# GridSearchCV with accuracy scoring
grid = GridSearchCV(
    rf,
    params,
    scoring="accuracy",
    n_jobs=-1  # Grid search itself can also use multiple cores
)


grid.fit(X_train, y_train)


print(grid.best_params_)

# Initialize and train a RandomForestClassifier with specific hyperparameters


rf = RandomForestClassifier(**{
    'n_estimators': 850,  
    'max_samples': 0.4,   
    'max_depth': 10,      
    'min_samples_leaf': 5,  
    'bootstrap': True     
})


rf = rf.fit(X_train, y_train)


print(f"Train Accuracy: {rf.score(X_train, y_train)}")


print(f"Test Accuracy: {rf.score(X_test, y_test)}")




# Get probability predictions for the positive class
y_probs = lr.predict_proba(X_test)[:, 1]

# Compute Receiver Operating Characteristic (ROC) curve points
fpr1, tpr1, thresholds = roc_curve(y_test, y_probs)

# Calculate the Area Under the Curve (AUC) score
auc_score = auc(fpr1, tpr1)

auc_score

# 1. Create a DataFrame to display the feature importance of each feature in the Random Forest model.
#    - "feature": This column contains the names of the features (extracted from X_train columns).
#    - "importance": This column contains the importance scores of each feature, as computed by the Random Forest model 
#      (accessible via rf.feature_importances_).
# 2. Sort the DataFrame by the "importance" column in descending order so that the most important features appear first.
# 3. Use iloc[:20] to select only the top 20 most important features.
importance = pd.DataFrame(
    {"feature": X_train.columns,
    "importance": rf.feature_importances_}
).sort_values("importance", ascending=False).iloc[:20]
# 4. Use Seaborn's barplot to create a bar chart that visualizes the top 20 important features.
#    - The x-axis represents the importance score of each feature.
#    - The y-axis represents the feature names.
sns.barplot(importance, x="importance", y="feature")
#Age is the most impectful feature - older customers are more likely to churn.

